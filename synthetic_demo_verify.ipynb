{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3405bd25",
   "metadata": {
    "id": "3405bd25"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log, e\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "torch.manual_seed(11)\n",
    "np.random.seed(11)\n",
    "random.seed(11)\n",
    "\n",
    "plt.rcParams.update({'font.size': 13})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be1a23c5",
   "metadata": {
    "id": "be1a23c5"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_dim, out_channel, patch_num, small=True, activation='linear'):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, out_channel*2, int(input_dim/patch_num), int(input_dim/patch_num))        \n",
    "        # small initialization\n",
    "        if small:\n",
    "            self.conv1.weight = torch.nn.Parameter(self.conv1.weight*0.001) \n",
    "            self.conv1.bias = torch.nn.Parameter(self.conv1.bias*0.001) \n",
    "        self.out_channel = out_channel\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if self.activation == 'cubic':\n",
    "            x = x**3\n",
    "        elif self.activation == 'relu':\n",
    "            x = F.relu(x)\n",
    "        elif self.activation == 'celu':\n",
    "            x = F.celu(x)\n",
    "        elif self.activation == 'gelu':\n",
    "            x = F.gelu(x)\n",
    "        elif self.activation == 'tanh':\n",
    "            x = torch.tanh(x)\n",
    "        x = torch.sum(x,2)\n",
    "        output = torch.stack([torch.sum(x[:,:self.out_channel],1), torch.sum(x[:,self.out_channel:],1)]).transpose(1,0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bedec",
   "metadata": {
    "id": "929bedec"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc373c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single(model, criterion, data, labels, optimizers, epochs):\n",
    "    \n",
    "    min_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):  \n",
    "        for optimizer in optimizers:\n",
    "            optimizer.zero_grad()\n",
    "        outputs = model(data) \n",
    "        loss = criterion(outputs, labels) \n",
    "        \n",
    "        if loss.item() <= min_loss:\n",
    "            min_loss = loss.item()\n",
    "        elif epoch > 500 and loss > min_loss+0.02:\n",
    "            break\n",
    "        \n",
    "        loss.backward() \n",
    "                \n",
    "        for optimizer in optimizers:\n",
    "            optimizer.step()\n",
    "        \n",
    "        if epoch%100 == 0:   \n",
    "            print('Epoch %d --- loss: %.3f' %\n",
    "                    (epoch + 1, loss.item()))\n",
    "    print('Finished Training')\n",
    "\n",
    "    \n",
    "def test_single(model, criterion, data, labels):\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(data) # ,_\n",
    "        predicted = torch.max(outputs.data, 1).indices\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the %d test images: %.4f %%' % (data.shape[0],\n",
    "        100 * correct / data.shape[0]))\n",
    "    \n",
    "    return 100 * correct / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aaef9c",
   "metadata": {
    "id": "61aaef9c"
   },
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfa9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NUM = 16000\n",
    "CLUSTER_NUM = 4\n",
    "EXPERT_NUM = 8\n",
    "PATCH_NUM = 4\n",
    "PATCH_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b853f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.load('synthetic_data_verify/train_data.pt')\n",
    "training_labels = torch.load('synthetic_data_verify/train_labels.pt')\n",
    "\n",
    "test_data = torch.load('synthetic_data_verify/test_data.pt')\n",
    "test_labels = torch.load('synthetic_data_verify/test_labels.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94c844",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb25871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 --- loss: 10.429\n",
      "Epoch 101 --- loss: 0.382\n",
      "Epoch 201 --- loss: 0.382\n",
      "Epoch 301 --- loss: 0.381\n",
      "Epoch 401 --- loss: 0.383\n",
      "Epoch 501 --- loss: 0.382\n",
      "Epoch 601 --- loss: 0.383\n",
      "Epoch 701 --- loss: 0.382\n",
      "Epoch 801 --- loss: 0.385\n",
      "Finished Training\n",
      "Accuracy of the network on the 16000 test images: 75.1688 %\n",
      "Accuracy of the network on the 16000 test images: 74.5438 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.54375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 801\n",
    "\n",
    "linear_single = ConvNet(200, 64, PATCH_NUM, small=False).cuda() \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.Adam(linear_single.parameters(), lr=0.001, weight_decay=5e-4) \n",
    "train_single(linear_single, criterion, training_data, training_labels, [optimizer], num_epochs)\n",
    "\n",
    "test_single(linear_single, criterion, training_data, training_labels)\n",
    "test_single(linear_single, criterion, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "045815de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 --- loss: 44.965\n",
      "Epoch 101 --- loss: 1.177\n",
      "Epoch 201 --- loss: 0.522\n",
      "Epoch 301 --- loss: 0.343\n",
      "Epoch 401 --- loss: 0.244\n",
      "Epoch 501 --- loss: 0.217\n",
      "Finished Training\n",
      "Accuracy of the network on the 16000 test images: 90.1250 %\n",
      "Accuracy of the network on the 16000 test images: 72.6875 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.6875"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 801\n",
    "\n",
    "nonlinear_single = ConvNet(200, 64, PATCH_NUM, small=False, activation='cubic').cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.Adam(nonlinear_single.parameters(), lr=0.01, weight_decay=5e-4) \n",
    "train_single(nonlinear_single, criterion, training_data, training_labels, \n",
    "                                                           [optimizer], num_epochs)\n",
    "\n",
    "test_single(nonlinear_single, criterion, training_data, training_labels)\n",
    "test_single(nonlinear_single, criterion, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fded964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 --- loss: 7.271\n",
      "Epoch 101 --- loss: 0.481\n",
      "Epoch 201 --- loss: 0.359\n",
      "Epoch 301 --- loss: 0.320\n",
      "Epoch 401 --- loss: 0.294\n",
      "Epoch 501 --- loss: 0.274\n",
      "Finished Training\n",
      "Accuracy of the network on the 16000 test images: 85.4562 %\n",
      "Accuracy of the network on the 16000 test images: 74.4938 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.49375"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 801\n",
    "\n",
    "nonlinear_single = ConvNet(200, 64, PATCH_NUM, small=False, activation='relu').cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.Adam(nonlinear_single.parameters(), lr=0.01, weight_decay=5e-4) \n",
    "train_single(nonlinear_single, criterion, training_data, training_labels, \n",
    "                                                           [optimizer], num_epochs)\n",
    "\n",
    "test_single(nonlinear_single, criterion, training_data, training_labels)\n",
    "test_single(nonlinear_single, criterion, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecfd5088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 --- loss: 5.692\n",
      "Epoch 101 --- loss: 0.536\n",
      "Epoch 201 --- loss: 0.603\n",
      "Epoch 301 --- loss: 0.673\n",
      "Epoch 401 --- loss: 0.610\n",
      "Epoch 501 --- loss: 0.716\n",
      "Finished Training\n",
      "Accuracy of the network on the 16000 test images: 81.0000 %\n",
      "Accuracy of the network on the 16000 test images: 76.9125 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76.9125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 801\n",
    "\n",
    "nonlinear_single = ConvNet(200, 64, PATCH_NUM, small=False, activation='celu').cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.Adam(nonlinear_single.parameters(), lr=0.01, weight_decay=5e-4) \n",
    "train_single(nonlinear_single, criterion, training_data, training_labels, \n",
    "                                                           [optimizer], num_epochs)\n",
    "\n",
    "test_single(nonlinear_single, criterion, training_data, training_labels)\n",
    "test_single(nonlinear_single, criterion, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daebc39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 --- loss: 6.210\n",
      "Epoch 101 --- loss: 0.472\n",
      "Epoch 201 --- loss: 0.419\n",
      "Epoch 301 --- loss: 0.393\n",
      "Epoch 401 --- loss: 0.369\n",
      "Epoch 501 --- loss: 0.326\n",
      "Finished Training\n",
      "Accuracy of the network on the 16000 test images: 80.2000 %\n",
      "Accuracy of the network on the 16000 test images: 74.0062 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.00625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 801\n",
    "\n",
    "nonlinear_single = ConvNet(200, 64, PATCH_NUM, small=False, activation='gelu').cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.Adam(nonlinear_single.parameters(), lr=0.01, weight_decay=5e-4) \n",
    "train_single(nonlinear_single, criterion, training_data, training_labels, \n",
    "                                                           [optimizer], num_epochs)\n",
    "\n",
    "test_single(nonlinear_single, criterion, training_data, training_labels)\n",
    "test_single(nonlinear_single, criterion, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea8d0b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 --- loss: 5.375\n",
      "Epoch 101 --- loss: 0.348\n",
      "Epoch 201 --- loss: 0.254\n",
      "Epoch 301 --- loss: 0.192\n",
      "Epoch 401 --- loss: 0.161\n",
      "Epoch 501 --- loss: 0.134\n",
      "Finished Training\n",
      "Accuracy of the network on the 16000 test images: 93.5125 %\n",
      "Accuracy of the network on the 16000 test images: 74.7562 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.75625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 801\n",
    "\n",
    "nonlinear_single = ConvNet(200, 64, PATCH_NUM, small=False, activation='tanh').cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.Adam(nonlinear_single.parameters(), lr=0.01, weight_decay=5e-4) \n",
    "train_single(nonlinear_single, criterion, training_data, training_labels, \n",
    "                                                           [optimizer], num_epochs)\n",
    "\n",
    "test_single(nonlinear_single, criterion, training_data, training_labels)\n",
    "test_single(nonlinear_single, criterion, test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of tensorpowernew.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
